{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>diaryofagameaddict.com</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>espdesign.com.au</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>iamagameaddict.com</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>kalantzis.net</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>slightlyoffcenter.net</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url label\n",
       "0  diaryofagameaddict.com   bad\n",
       "1        espdesign.com.au   bad\n",
       "2      iamagameaddict.com   bad\n",
       "3           kalantzis.net   bad\n",
       "4   slightlyoffcenter.net   bad"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['diaryofagameaddict.com', 'bad'],\n",
       "       ['espdesign.com.au', 'bad'],\n",
       "       ['iamagameaddict.com', 'bad'],\n",
       "       ...,\n",
       "       ['apple-iclods.org/', 'bad'],\n",
       "       ['apple-uptoday.org/', 'bad'],\n",
       "       ['apple-search.info', 'bad']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import URLFeatures\n",
    "\n",
    "from pprint import pprint \n",
    "import re\n",
    "def get_meta(url):\n",
    "\n",
    "\n",
    "    def get_length_of_primary(url):\n",
    "        return len(url.split('//')[-1].split('/')[0])\n",
    "\n",
    "    def get_number_of_dots(url):\n",
    "        return len(url.split('.')) - 1\n",
    "\n",
    "    def check_if_url_has_ip(url):\n",
    "        return True if re.match(r'http://\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}/.*', url) else False\n",
    "\n",
    "    def get_prop(property_list):\n",
    "        if isinstance(property_list, list):\n",
    "            return property_list[0], len(property_list)\n",
    "        else:\n",
    "            return property_list, 1\n",
    "\n",
    "    def get_words_from_URL(url):\n",
    "        words = re.compile(r'[\\:/?=\\-&.]+',re.UNICODE).split(url)\n",
    "        sortedwords = sorted(words, key=len)\n",
    "        average = sum([len(wrd) for wrd in words])/len(words)\n",
    "        return len(sortedwords[-1]), len(sortedwords[0]), average\n",
    "\n",
    "\n",
    "\n",
    "    obj = URLFeatures(url)\n",
    "    extracted = obj.to_dict()\n",
    "    extracted['actual_nameservers'], extracted['actual_nameservers_count'] = get_prop(extracted['actual_nameservers']) \n",
    "    extracted['whois_nameservers'], extracted['whois_nameservers_count'] = get_prop(extracted['whois_nameservers']) \n",
    "    extracted['emails'], extracted['emails_count'] = get_prop(extracted['emails']) \n",
    "    extracted['lifetime'] = (pd.to_datetime(extracted['expiration_date']) - pd.to_datetime(extracted['creation_date'])).days\n",
    "    extracted['length'] = len(url)\n",
    "    extracted['length_of_primary'] = get_length_of_primary(url)\n",
    "    extracted['number_of_dots'] = get_number_of_dots(url)\n",
    "    extracted['has_ip'] = check_if_url_has_ip(url)\n",
    "    extracted['longest_words'], extracted['shortest_words'], extracted['avg_words'] = get_words_from_URL(url)\n",
    "    return pd.DataFrame(extracted, index=[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tq\n",
    "%matplotlib inline  \n",
    "res = pd.DataFrame()\n",
    "fail = pd.DataFrame()\n",
    "def process_row(row):\n",
    "    try:\n",
    "        r = get_meta(row[0])\n",
    "        r[0], r[1] = row[0], row[1]\n",
    "        return r\n",
    "    except:\n",
    "        r = pd.DataFrame()\n",
    "        r[0], r[1] = row[0], row[1]\n",
    "        return r\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "unable to cache TLDs in file /usr/local/lib/python3.5/dist-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/usr/local/lib/python3.5/dist-packages/tldextract/.tld_set'\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "p = multiprocessing.Pool(50)\n",
    "for x in p.imap_unordered(process_row, df.values):\n",
    "    if len(x.columns)>2:\n",
    "        try:\n",
    "            res = pd.read_csv('dataset_new.csv')\n",
    "            if len(res%15000 == 0):\n",
    "                res.to_csv('dataset_new_ckpt.csv', index=False, encoding='utf-8')\n",
    "        except:\n",
    "            pass\n",
    "        res = res.append(x, ignore_index=True)\n",
    "        \n",
    "        res.to_csv('dataset_new.csv', index=False, encoding='utf-8')\n",
    "    else:\n",
    "        try:\n",
    "            fail = pd.read_csv('failed_new.csv')\n",
    "        except:\n",
    "            pass\n",
    "        fail = fail.append(x, ignore_index=True)\n",
    "        fail.to_csv('failed_new.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9838393207520245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def getTokens(input):\n",
    "    tokensBySlash = str(input.encode('utf-8')).split('/')#get tokens after splitting by slash\n",
    "    allTokens = []\n",
    "    for i in tokensBySlash:\n",
    "        tokens = str(i).split('-')#get tokens after splitting by dash\n",
    "        tokensByDot = []\n",
    "        for j in range(0,len(tokens)):\n",
    "            tempTokens = str(tokens[j]).split('.')#get tokens after splitting by dot\n",
    "            tokensByDot = tokensByDot + tempTokens\n",
    "        allTokens = allTokens + tokens + tokensByDot\n",
    "    allTokens = list(set(allTokens))#remove redundant tokens\n",
    "    if 'com' in allTokens:\n",
    "        allTokens.remove('com')#removing .com since it occurs a lot of times and it should not be included in our features\n",
    "    return allTokens\n",
    "\n",
    "\n",
    "allurls = 'data/data.csv'#path to our all urls file\n",
    "allurlscsv = pd.read_csv(allurls,',',error_bad_lines=False)\t#reading file\n",
    "allurlsdata = pd.DataFrame(allurlscsv)#converting to a dataframe\n",
    "\n",
    "allurlsdata = np.array(allurlsdata)#converting it into an array\n",
    "random.shuffle(allurlsdata)#shuffling\n",
    "\n",
    "y = [d[1] for d in allurlsdata]#all labels \n",
    "corpus = [d[0] for d in allurlsdata]#all urls corresponding to a label (either good or bad)\n",
    "vectorizer = TfidfVectorizer(tokenizer=getTokens)#get a vector for each url but use our customized tokenizer\n",
    "X = vectorizer.fit_transform(corpus)#get the X vector\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)#split into training and testing set 80/20 ratio\n",
    "\n",
    "lgs = LogisticRegression()#using logistic regression\n",
    "lgs.fit(X_train, y_train)\n",
    "print(lgs.score(X_test, y_test))#pring the score. It comes out to be 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x395281 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
